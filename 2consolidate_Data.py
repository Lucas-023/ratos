# consolidate_data.py - Vers√£o Ultraest√°vel (Memmap + Grava√ß√£o Segura + Limpeza de NaN)

import pandas as pd
import numpy as np
from pathlib import Path
from tqdm import tqdm
from typing import List, Any
import os 

# =========================================================
# CONFIGURA√á√ïES E PAR√ÇMETROS
# =========================================================

# üö® AJUSTE AQUI: Caminho para os arquivos Parquet *PROCESSADOS* de TREINO üö®
BASE_PATH_TRAIN = Path("MABe-mouse-behavior-detection/processed_videos_final_fixed") 

OUTPUT_X = "consolidated_X.npy"    
OUTPUT_Y = "consolidated_Y.csv"    
X_MEAN_PATH = "X_mean.npy"         
X_STD_PATH = "X_std.npy"           

# --- DEFINI√á√ïES DE COLUNAS ---
try:
    from dataloader import FEATURE_COLUMNS, TARGET_COLUMN
except ImportError:
    print("‚ö†Ô∏è Aviso: dataloader.py n√£o encontrado. Usando defini√ß√µes mockadas.")
    FEATURE_COLUMNS = [f'x_{i}' for i in range(1, 118)]
    TARGET_COLUMN = 'behavior'

N_FEATURES = len(FEATURE_COLUMNS)
parquet_files = list(BASE_PATH_TRAIN.rglob("*.parquet"))

if not parquet_files:
    print(f"‚ùå NENHUM arquivo Parquet encontrado em {BASE_PATH_TRAIN.resolve()}.")
    exit()

# =========================================================
# FUN√á√ÉO AUXILIAR: Extra√ß√£o Segura de Labels
# =========================================================

def safe_extract_labels(label_raw: Any) -> List[str]:
    """
    Trata formatos de labels e retorna uma lista de labels v√°lidas.
    """
    if isinstance(label_raw, (list, np.ndarray, pd.Series)):
         return [str(l).strip() for l in label_raw if str(l).strip()]
    if pd.isna(label_raw): 
        return []
    label_str = str(label_raw).strip()
    if not label_str or label_str.lower() in ('nan', '0.0', '0'):
        return []
    return [l.strip() for l in label_str.split(';') if l.strip()]


# =========================================================
# 1. PR√â-C√ÅLCULO DO TAMANHO TOTAL (PASSAGEM 0)
# =========================================================

total_frames = 0
print("üîç Calculando o n√∫mero total de frames em todos os arquivos...")
for file_path in tqdm(parquet_files, desc="Contando Frames"):
    try:
        df_temp = pd.read_parquet(file_path, engine='fastparquet', columns=[TARGET_COLUMN])
        total_frames += df_temp.shape[0]
    except Exception as e:
        print(f"\n‚ö†Ô∏è ERRO ao contar frames em {file_path.name}: {e}. Pulando.")

if total_frames == 0:
    print("Nenhum frame v√°lido encontrado para consolida√ß√£o. Saindo.")
    exit()

print(f"‚úÖ Total de frames a serem consolidados: {total_frames}")


# =========================================================
# 2. C√ÅLCULO DE ESTAT√çSTICAS (PRIMEIRA PASSAGEM)
# =========================================================

sum_x = np.zeros(N_FEATURES, dtype=np.float64)
sum_x_sq = np.zeros(N_FEATURES, dtype=np.float64)
total_frames_count = 0 

print("\nüìä Iniciando a PRIMEIRA PASSAGEM: C√°lculo de M√©dia e Vari√¢ncia...")
for file_path in tqdm(parquet_files, desc="Passagem 1/2: Calculando Estat√≠sticas"):
    try:
        df = pd.read_parquet(file_path, engine='fastparquet')
        features_df = df.reindex(columns=FEATURE_COLUMNS, fill_value=0.0)
        features_np = features_df.values.astype(np.float64) 
        
        sum_x += np.sum(features_np, axis=0)
        sum_x_sq += np.sum(features_np**2, axis=0)
        total_frames_count += len(features_np)
        
    except Exception as e:
        print(f"\n‚ö†Ô∏è ERRO no c√°lculo de estat√≠sticas em {file_path.name}: {e}. Pulando.")
        continue

# --- C√°lculo Final do Z-Score ---
X_mean = sum_x / total_frames_count
X_var = (sum_x_sq / total_frames_count) - (X_mean**2)
X_std = np.sqrt(X_var)

# CORRE√á√ÉO CR√çTICA DE ESTABILIDADE DO STD
EPSILON = 1e-8
X_std[X_std < EPSILON] = EPSILON 
print(f"   STD M√çNIMO (Ap√≥s corre√ß√£o): {np.min(X_std):.1e}")

np.save(X_MEAN_PATH, X_mean.astype(np.float32))
np.save(X_STD_PATH, X_std.astype(np.float32))

print(f"‚úÖ Estat√≠sticas calculadas e salvas em {X_MEAN_PATH} e {X_STD_PATH}.")


# =========================================================
# 3. CONSOLIDA√á√ÉO, NORMALIZA√á√ÉO E ESCRITA (SEGUNDA PASSAGEM - MEMMAP SEGURO)
# =========================================================

# PR√â-ALOCA√á√ÉO COM MEMMAP (Baixo uso de RAM durante a escrita)
print(f"\nPr√©-alocando arquivo tempor√°rio ({total_frames} linhas x {N_FEATURES} features) via Memmap...")
TEMP_X_PATH = "temp_" + OUTPUT_X
X_memmap_temp = np.memmap(
    TEMP_X_PATH, 
    dtype=np.float32, 
    mode='w+', 
    shape=(total_frames, N_FEATURES)
)

# Reseta o arquivo CSV de labels e escreve o cabe√ßalho
with open(OUTPUT_Y, 'w', encoding='utf-8') as f_csv:
    f_csv.write(f"{TARGET_COLUMN}\n")

current_index = 0
print("üöÄ Iniciando a SEGUNDA PASSAGEM: Normaliza√ß√£o e Grava√ß√£o no Memmap...")

for file_path in tqdm(parquet_files, desc="Passagem 2/2: Gravando Normalizado"):
    try:
        df = pd.read_parquet(file_path, engine='fastparquet')
        n_rows = len(df)
        
        # --- A) Grava√ß√£o das FEATURES (X) ---
        features_df = df.reindex(columns=FEATURE_COLUMNS, fill_value=0.0)
        features_np = features_df.values.astype(np.float32)
        
        # NORMALIZA√á√ÉO Z-SCORE 
        features_normalized = (features_np - X_mean.astype(np.float32)) / X_std.astype(np.float32)
        
        # üö® CORRE√á√ÉO CR√çTICA DE NAN (IMPUTA√á√ÉO) üö®
        # Substitui qualquer NaN gerado (ou herdado) por 0.0
        features_normalized[np.isnan(features_normalized)] = 0.0
        
        # Escreve o bloco de dados NORMALIZADO no memmap tempor√°rio
        X_memmap_temp[current_index : current_index + n_rows] = features_normalized
        
        # --- B) Grava√ß√£o dos LABELS (Y) ---
        labels_series = df[TARGET_COLUMN].apply(
            lambda x: ";".join(safe_extract_labels(x))
        )
        labels_series.to_csv(OUTPUT_Y, mode='a', index=False, header=False, encoding='utf-8')
        
        current_index += n_rows
        
    except Exception as e:
        print(f"\n‚ö†Ô∏è ERRO (PULANDO ARQUIVO) ao normalizar e gravar {file_path.name}: {e}. A consolida√ß√£o continua.")
        continue 

# Garante que todos os dados tenham sido escritos no disco
X_memmap_temp.flush() 

# üö® ETAPA CR√çTICA DE CORRE√á√ÉO DO FORMATO üö®
print("\nüíæ SALVAMENTO SEGURO: Carregando (√∫ltima vez) e re-salvando o Memmap com np.save...")
try:
    # Carrega o array inteiro na RAM (Se 32GB aguentar, funcionar√°)
    X_final_array = np.array(X_memmap_temp) 
    
    # Salva o array de forma segura com np.save padr√£o
    np.save(OUTPUT_X, X_final_array)
    
    # Remove o arquivo tempor√°rio
    os.remove(TEMP_X_PATH)

    print("\n----------------------------------------------------")
    print(f"‚úÖ CONSOLIDA√á√ÉO CONCLU√çDA. O arquivo final {OUTPUT_X} foi salvo de forma segura.")
    print("----------------------------------------------------")

except Exception as e:
    print(f"\n‚ùå ERRO FATAL na re-grava√ß√£o: {e}. O problema √© de mem√≥ria/sistema operacional.")
    print("O arquivo FINAL N√ÉO foi criado. Tente criar um novo ambiente Python.")