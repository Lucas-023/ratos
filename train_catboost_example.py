"""
Exemplo de treinamento com CatBoost usando os dados processados.

Este script demonstra como:
1. Carregar os dados consolidados
2. Preparar vari√°veis categ√≥ricas
3. Treinar um modelo CatBoost
4. Fazer predi√ß√µes multi-label
"""

import numpy as np
import pandas as pd
import pickle
from pathlib import Path
from catboost import CatBoostClassifier, Pool
from sklearn.model_selection import train_test_split
from sklearn.metrics import hamming_loss, accuracy_score
import warnings
warnings.filterwarnings('ignore')

# =================================================================
# CONFIGURA√á√ïES
# =================================================================

X_PATH = "consolidated_X_catboost.npy"
Y_PATH = "consolidated_Y_catboost.csv"
CATEGORICAL_PATH = "consolidated_X_catboost_categorical.parquet"
CATEGORICAL_INFO_PATH = "categorical_info_catboost.pkl"

# =================================================================
# CARREGAMENTO DE DADOS
# =================================================================

print("üìÇ Carregando dados...")

# Carrega features num√©ricas
X = np.load(X_PATH)
print(f"‚úÖ Features num√©ricas carregadas: {X.shape}")

# Carrega labels
y_df = pd.read_csv(Y_PATH)
print(f"‚úÖ Labels carregados: {len(y_df)} amostras")

# Processa labels para multi-label
def parse_multi_label(label_str):
    """Converte string de labels separados por ';' em lista."""
    if pd.isna(label_str) or label_str == '':
        return []
    return [l.strip() for l in str(label_str).split(';') if l.strip()]

# Cria matriz multi-label
all_labels = set()
for label_str in y_df['behavior']:
    labels = parse_multi_label(label_str)
    all_labels.update(labels)

all_labels = sorted(list(all_labels))
label_to_idx = {label: idx for idx, label in enumerate(all_labels)}
n_classes = len(all_labels)

print(f"‚úÖ Total de classes de comportamento: {n_classes}")
print(f"   Classes: {all_labels[:10]}..." if len(all_labels) > 10 else f"   Classes: {all_labels}")

# Cria matriz multi-hot
y_multi_hot = np.zeros((len(y_df), n_classes), dtype=np.float32)
for idx, label_str in enumerate(y_df['behavior']):
    labels = parse_multi_label(label_str)
    for label in labels:
        if label in label_to_idx:
            y_multi_hot[idx, label_to_idx[label]] = 1.0

print(f"‚úÖ Matriz multi-label criada: {y_multi_hot.shape}")

# Carrega vari√°veis categ√≥ricas
cat_features_df = pd.read_parquet(CATEGORICAL_PATH)
print(f"‚úÖ Vari√°veis categ√≥ricas carregadas: {cat_features_df.shape}")

# Carrega informa√ß√µes sobre categ√≥ricas
with open(CATEGORICAL_INFO_PATH, 'rb') as f:
    categorical_info = pickle.load(f)

print(f"‚úÖ Informa√ß√µes sobre categ√≥ricas carregadas")

# =================================================================
# PREPARA√á√ÉO DE VARI√ÅVEIS CATEG√ìRICAS
# =================================================================

# Identifica √≠ndices das colunas categ√≥ricas no array X
# Como as categ√≥ricas est√£o em um DataFrame separado, precisamos concaten√°-las
# ou usar apenas as num√©ricas. Para este exemplo, vamos usar apenas as num√©ricas
# e adicionar as categ√≥ricas como features adicionais.

# Converte categ√≥ricas para √≠ndices num√©ricos (CatBoost requer isso)
cat_features_encoded = {}
cat_feature_indices = []

# Adiciona categ√≥ricas como colunas adicionais ao X
# (Alternativamente, voc√™ pode usar cat_features como par√¢metro separado no CatBoost)
for col_idx, col in enumerate(cat_features_df.columns):
    # Converte para √≠ndices categ√≥ricos
    unique_vals = categorical_info[col]['categories']
    val_to_idx = {val: idx for idx, val in enumerate(unique_vals)}
    
    # Mapeia valores para √≠ndices
    encoded = cat_features_df[col].apply(
        lambda x: val_to_idx.get(str(x), len(unique_vals))  # Usa √∫ltimo √≠ndice para valores n√£o vistos
    ).values
    
    # Adiciona como coluna num√©rica ao X
    X = np.column_stack([X, encoded.astype(np.float32)])
    cat_feature_indices.append(X.shape[1] - 1)  # √çndice da √∫ltima coluna adicionada

print(f"‚úÖ Vari√°veis categ√≥ricas adicionadas. Total de features: {X.shape[1]}")
print(f"   √çndices das categ√≥ricas: {cat_feature_indices}")

# =================================================================
# DIVIS√ÉO TREINO/VALIDA√á√ÉO
# =================================================================

# Para multi-label, podemos usar train_test_split normalmente
X_train, X_val, y_train, y_val = train_test_split(
    X, y_multi_hot,
    test_size=0.2,
    random_state=42,
    shuffle=True
)

print(f"\nüìä Divis√£o dos dados:")
print(f"   Treino: {X_train.shape[0]} amostras")
print(f"   Valida√ß√£o: {X_val.shape[0]} amostras")

# =================================================================
# TREINAMENTO COM CATBOOST
# =================================================================

print("\nüöÄ Treinando modelo CatBoost...")

# Para multi-label, treinamos um classificador por classe (One-vs-Rest)
# ou usamos CatBoost com loss='MultiLogloss' (se suportado)

# Op√ß√£o 1: One-vs-Rest (mais comum para multi-label)
models = []
for class_idx in range(n_classes):
    if class_idx % 10 == 0:
        print(f"   Treinando classe {class_idx+1}/{n_classes}...")
    
    y_class = y_train[:, class_idx]
    
    # Pula classes sem exemplos positivos
    if y_class.sum() == 0:
        models.append(None)
        continue
    
    model = CatBoostClassifier(
        iterations=500,
        learning_rate=0.1,
        depth=6,
        loss_function='Logloss',
        eval_metric='AUC',
        random_seed=42,
        verbose=False,
        cat_features=cat_feature_indices,  # Especifica quais colunas s√£o categ√≥ricas
        task_type='CPU',  # Mude para 'GPU' se dispon√≠vel
    )
    
    # Treina
    model.fit(
        X_train, y_class,
        eval_set=(X_val, y_val[:, class_idx]),
        early_stopping_rounds=50,
        verbose=False
    )
    
    models.append(model)

print(f"‚úÖ {sum(1 for m in models if m is not None)} modelos treinados")

# =================================================================
# AVALIA√á√ÉO
# =================================================================

print("\nüìä Avaliando modelo...")

# Predi√ß√µes
y_pred_proba = np.zeros((X_val.shape[0], n_classes))
for class_idx, model in enumerate(models):
    if model is not None:
        y_pred_proba[:, class_idx] = model.predict_proba(X_val)[:, 1]

# Converte probabilidades em predi√ß√µes bin√°rias (threshold=0.5)
y_pred = (y_pred_proba >= 0.5).astype(int)

# M√©tricas
hamming = hamming_loss(y_val, y_pred)
subset_accuracy = accuracy_score(y_val, y_pred)

print(f"   Hamming Loss: {hamming:.4f} (menor √© melhor)")
print(f"   Subset Accuracy: {subset_accuracy:.4f} (maior √© melhor)")

# =================================================================
# SALVAMENTO DO MODELO
# =================================================================

print("\nüíæ Salvando modelos...")

model_dir = Path("catboost_models")
model_dir.mkdir(exist_ok=True)

# Salva cada modelo
for class_idx, model in enumerate(models):
    if model is not None:
        model_path = model_dir / f"catboost_class_{class_idx}_{all_labels[class_idx]}.cbm"
        model.save_model(str(model_path))

# Salva informa√ß√µes sobre labels
label_info = {
    'all_labels': all_labels,
    'label_to_idx': label_to_idx,
    'n_classes': n_classes,
    'cat_feature_indices': cat_feature_indices
}

with open(model_dir / "label_info.pkl", 'wb') as f:
    pickle.dump(label_info, f)

print(f"‚úÖ Modelos salvos em {model_dir}")

print("\n" + "="*60)
print("‚úÖ TREINAMENTO CONCLU√çDO")
print("="*60)
print("\nüí° Dicas para melhorar o modelo:")
print("   1. Ajuste hiperpar√¢metros (depth, learning_rate, iterations)")
print("   2. Use GPU se dispon√≠vel (task_type='GPU')")
print("   3. Experimente diferentes thresholds para predi√ß√µes bin√°rias")
print("   4. Use valida√ß√£o cruzada para avalia√ß√£o mais robusta")
print("   5. Considere usar CatBoost com MultiLogloss se dispon√≠vel")

