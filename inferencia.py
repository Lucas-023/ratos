import torch
import numpy as np
import pandas as pd
import pytorch_lightning as pl
from pathlib import Path
from torch.utils.data import Dataset, DataLoader
from tqdm import tqdm
import json 
import os 

# Importa as defini√ß√µes do seu script de treino
try:
    from optlstm import LSTMBehaviorModel, SEQ_LEN, INPUT_SIZE
except ImportError:
    print("‚ùå ERRO: N√£o foi poss√≠vel importar LSTMBehaviorModel ou constantes de optlstm.py")
    print("Verifique se optlstm.py e suas depend√™ncias est√£o no caminho correto.")
    exit()

# =========================================================
# CONFIGURA√á√ÉO DE INFER√äNCIA
# =========================================================

# üö® AJUSTE AQUI: Caminho para o CHECKPOINT (pesos) do seu melhor modelo treinado
# Certifique-se de que este caminho est√° correto.
CHECKPOINT_PATH = Path("lightning_logs/version_14/checkpoints/epoch=9-step=1113270.ckpt") 

# Caminhos dos arquivos
CONSOLIDATED_TEST_X_PATH = Path("consolidated_TEST_X.npy")
CONSOLIDATED_TEST_Y_PATH = Path("consolidated_TEST_Y.csv") 
BEHAVIOR_MAP_PATH = Path("behavior_map.json") 

# Configura√ß√µes de performance/sa√≠da
OUTPUT_PREDICTIONS_PATH = Path("./test_predictions_final_ANALYSIS.csv")
BATCH_SIZE = 512 
NUM_WORKERS = os.cpu_count() if os.name != 'nt' else 0
THRESHOLD = 0.5 

BEHAVIOR_MAP = None 

# =========================================================
# 1. Dataset de Infer√™ncia (L√™ apenas X)
# =========================================================

class TestInferenceDataset(Dataset):
    def __init__(self, x_file: Path, y_file: Path, seq_len: int):
        self.seq_len = seq_len
        
        df_y = pd.read_csv(y_file)
        self.total_frames = len(df_y)
        
        print(f"Carregando features de teste de: {x_file.name}")
        self.features = np.memmap(
            x_file, 
            dtype=np.float32, 
            mode='r', 
            shape=(self.total_frames, INPUT_SIZE) 
        )
        
        self.num_samples = self.total_frames - self.seq_len + 1
        self.output_frame_indices = np.arange(self.seq_len - 1, self.total_frames)

    def __len__(self):
        return self.num_samples

    def __getitem__(self, idx: int) -> tuple[torch.Tensor, int]:
        start = idx
        end = idx + self.seq_len
        
        X_np_seq = self.features[start:end, :]
        X_seq = torch.from_numpy(X_np_seq.copy()) 
        
        frame_index = self.output_frame_indices[idx]
        
        return X_seq, frame_index

# =========================================================
# 2. L√≥gica Principal de Infer√™ncia
# =========================================================

def run_test_inference(checkpoint_path: Path):
    global BEHAVIOR_MAP

    if not checkpoint_path.exists():
        print(f"‚ùå ERRO: Checkpoint n√£o encontrado em {checkpoint_path}")
        return

    # 1. Carregar o Mapa de Comportamento
    if BEHAVIOR_MAP_PATH.exists():
        with open(BEHAVIOR_MAP_PATH, "r") as f:
            loaded_map = json.load(f)
            BEHAVIOR_MAP = {int(k): v for k, v in loaded_map.items()}
    else:
        print(f"‚ùå ERRO: Arquivo de mapeamento {BEHAVIOR_MAP_PATH} n√£o encontrado.")
        print("Rode o optlstm.py para gerar behavior_map.json.")
        return

    # 2. Carregar o Modelo a partir do Checkpoint
    print(f"Carregando modelo a partir de: {checkpoint_path.name}")
    
    try:
        # Carrega o checkpoint completo do PyTorch
        checkpoint = torch.load(checkpoint_path, map_location="cpu") 
        hparams = checkpoint["hyper_parameters"]
    except Exception as e:
        print(f"‚ùå ERRO ao carregar o arquivo checkpoint: {e}")
        return

    # üö® PASSO CR√çTICO: Remove a chave problem√°tica (necess√°rio para compatibilidade com checkpoints antigos)
    if "loss_fn.pos_weight" in checkpoint["state_dict"]:
        del checkpoint["state_dict"]["loss_fn.pos_weight"]
        print("‚úÖ Chave 'loss_fn.pos_weight' removida com sucesso do estado de dicion√°rio.")
    
    # üö® CORRE√á√ÉO FINAL DO TypeError: Instancia o modelo manualmente e carrega o estado
    
    # Obt√©m weight_decay, com fallback para 0.0 caso o checkpoint n√£o tenha sido treinado com ele
    weight_decay_val = hparams.get('weight_decay', 0.0) 

    # Instancia o modelo com os hparams salvos (sem 'pos_weight_tensor')
    model = LSTMBehaviorModel(
        input_size=hparams['input_size'],
        hidden_size=hparams['hidden_size'],
        num_layers=hparams['num_layers'],
        num_classes=len(BEHAVIOR_MAP), # Usa o n√∫mero correto de classes do mapa carregado
        lr=hparams['lr'],
        weight_decay=weight_decay_val  # ‚úÖ NOVO: Adiciona weight_decay
        # pos_weight_tensor removido
    )
    
    # Carrega o estado de dicion√°rio MODIFICADO
    model.load_state_dict(checkpoint["state_dict"], strict=True)
    
    model.eval() # Coloca o modelo em modo de avalia√ß√£o
    
    # 3. Configurar o Dataset e DataLoader
    test_dataset = TestInferenceDataset(CONSOLIDATED_TEST_X_PATH, CONSOLIDATED_TEST_Y_PATH, seq_len=SEQ_LEN)
    test_loader = DataLoader(
        test_dataset, 
        batch_size=BATCH_SIZE, 
        shuffle=False, 
        num_workers=NUM_WORKERS
    )
    
    # 4. Executar a Infer√™ncia e Coletar Probabilidades
    print("\nIniciando infer√™ncia e coletando probabilidades...")
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)

    all_probabilities = []
    all_frame_indices = []
    
    with torch.no_grad():
        for features, frame_indices in tqdm(test_loader, desc="Fazendo Predi√ß√µes"):
            features = features.to(device)
            logits = model(features)
            probabilities = torch.sigmoid(logits)
            
            all_probabilities.extend(probabilities.cpu().tolist())
            all_frame_indices.extend(frame_indices.cpu().tolist())

    # 5. Salvar as Predi√ß√µes e Probabilidades para An√°lise
    
    prob_columns = [f"prob_{BEHAVIOR_MAP.get(i, f'CLASSE_{i}')}" for i in range(len(BEHAVIOR_MAP))]
    
    prob_df = pd.DataFrame(all_probabilities, columns=prob_columns)
    
    output_df = pd.DataFrame({'frame': all_frame_indices})
    output_df = pd.concat([output_df, prob_df], axis=1)

    # 1. Predi√ß√£o Multi-Label (Threshold 0.5)
    predicted_multi_label_df = (prob_df > THRESHOLD).astype(int)
    predicted_multi_label_list = predicted_multi_label_df.apply(
        lambda row: ';'.join([col.replace('prob_', '') for col, val in row.items() if val == 1]), axis=1
    )
    output_df[f'predicted_behaviors_multi_label_T{int(THRESHOLD*100)}'] = predicted_multi_label_list
    
    # 2. Predi√ß√£o Single-Label (Classe com maior score)
    output_df['predicted_behavior_argmax'] = prob_df.idxmax(axis=1).apply(lambda x: x.replace('prob_', ''))
    
    output_df.to_csv(OUTPUT_PREDICTIONS_PATH, index=False)
    
    print("\n=======================================================")
    print("‚úÖ INFER√äNCIA CONCLU√çDA E SALVA PARA AN√ÅLISE!")
    print(f"Predi√ß√µes salvas em: {OUTPUT_PREDICTIONS_PATH.resolve()}")
    print("üî• AGORA, ANALISE AS COLUNAS 'prob_...' para avaliar o aprendizado.")
    print("=======================================================")

if __name__ == "__main__":
    
    if CHECKPOINT_PATH.name == "PATH_TO_YOUR_BEST_MODEL.ckpt":
        print("\n---------------------------------------------------------")
        print("‚ö†Ô∏è POR FAVOR, AJUSTE A VARI√ÅVEL CHECKPOINT_PATH NO IN√çCIO DO SCRIPT.")
        print("---------------------------------------------------------")
    else:
        run_test_inference(CHECKPOINT_PATH)